1 16 16 4096 1 1 0 0 0  : 1.2366
4 64 16 4096 64 4 0 0 0  : 0.77722
1 64 16 4096 16 16 0 15 0  : 0.85804
12 16 16 4096 32 32 2 12 0  : 0.83551
12 32 16 4096 16 8 1 4 0  : 0.77481
12 64 16 4096 1 1 1 0 0  : 0.8073
12 64 16 4096 64 4 1 0 0  : 0.77308
12 8 16 4096 64 32 0 24 0  : 0.99104
16 16 16 4096 32 32 3 7 0  : 0.83321
16 32 16 4096 32 32 0 17 0  : 0.77809
16 64 16 4096 16 16 2 7 0  : 0.7681
16 64 16 4096 8 2 1 1 0  : 0.76818
16 8 16 4096 64 32 2 17 0  : 0.98886
2 64 16 4096 16 16 0 1 0  : 0.8055
20 16 16 4096 2 2 0 0 1  : 0.79604
20 16 16 4096 64 8 3 2 0  : 0.89711
20 32 16 4096 32 8 2 7 0  : 0.7754
20 64 16 4096 16 4 4 3 0  : 0.76785
20 64 16 4096 64 32 4 8 0  : 0.77451
20 8 16 4096 32 32 4 5 0  : 0.94041
4 16 16 4096 32 32 0 1 0  : 0.84407
4 8 16 4096 2 2 0 0 0  : 0.89989
6 64 16 4096 32 2 0 0 1  : 0.78224
8 16 16 4096 64 32 0 21 0  : 0.89406
8 64 16 4096 32 32 0 18 0  : 0.7718
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0538969 ... No improvement for 0 generations.

Current fitness: 0.051256 ... No improvement for 0 generations.

Current fitness: 0.053682 ... No improvement for 1 generations.

Current fitness: 0.0514855 ... No improvement for 2 generations.

Current fitness: 0.0468127 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0479922 ... No improvement for 1 generations.

Current fitness: 0.0479922 ... No improvement for 2 generations.

Current fitness: 0.047626 ... No improvement for 3 generations.

Current fitness: 0.047626 ... No improvement for 4 generations.

Current fitness: 0.0448225 ... No improvement for 0 generations.

Current fitness: 0.0448225 ... No improvement for 1 generations.

Current fitness: 0.0448225 ... No improvement for 2 generations.

Current fitness: 0.0448225 ... No improvement for 3 generations.

Current fitness: 0.0443842 ... No improvement for 0 generations.

Current fitness: 0.0443761 ... No improvement for 0 generations.

Current fitness: 0.0403177 ... No improvement for 0 generations.

Current fitness: 0.0397727 ... No improvement for 0 generations.

Current fitness: 0.0424055 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0212122 ... No improvement for 0 generations.

Current fitness: 0.0229059 ... No improvement for 1 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0169412 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0163596 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0163602 ... No improvement for 1 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0148166 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0148266 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0126488 ... No improvement for 0 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.012874 ... No improvement for 1 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0154352 ... No improvement for 2 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0129827 ... No improvement for 3 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0120093 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0131497 ... No improvement for 1 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0142693 ... No improvement for 2 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0108993 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0130371 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00901514 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26
42
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
2729

WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00901514 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0123942 ... No improvement for 2 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00901513 ... No improvement for 3 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0121595 ... No improvement for 4 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0123938 ... No improvement for 5 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0128499 ... No improvement for 6 generations.
43

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0123938 ... No improvement for 7 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0113378 ... No improvement for 8 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
50

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0121264 ... No improvement for 9 generations.
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0129588 ... No improvement for 10 generations.
30
27
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0112792 ... No improvement for 11 generations.

Converged after 46 generations.
