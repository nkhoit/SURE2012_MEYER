1 16 16 4096 1 1 0 0 0  : 1.2366
16 8 16 4096 32 32 0 0 0  : 0.94078
4 64 16 4096 64 32 0 0 0  : 0.77895
1 16 16 4096 32 32 0 14 0  : 0.9655
1 64 16 4096 16 16 0 13 0  : 0.85804
1 8 16 4096 64 32 0 8 0  : 1.1778
12 16 16 4096 32 32 2 1 0  : 0.83551
12 16 16 4096 64 32 3 13 0  : 0.89429
12 32 16 4096 16 8 1 0 0  : 0.77481
12 32 16 4096 4 4 2 3 0  : 0.7802
12 32 16 4096 8 8 3 5 0  : 0.77509
12 64 16 4096 32 32 2 5 0  : 0.77155
12 64 16 4096 64 32 3 9 0  : 0.77603
12 8 16 4096 2 1 0 0 1  : 0.86106
12 8 16 4096 64 32 0 18 0  : 0.99104
16 16 16 4096 16 16 0 4 0  : 0.8001
16 16 16 4096 32 32 3 28 0  : 0.83321
16 16 16 4096 64 8 0 6 0  : 0.89666
16 32 16 4096 32 32 0 0 1  : 0.77809
16 32 16 4096 64 32 1 12 0  : 0.81237
16 64 16 4096 16 16 2 11 0  : 0.7681
16 64 16 4096 32 4 3 1 0  : 0.76888
16 64 16 4096 64 8 3 7 0  : 0.7731
16 8 16 4096 32 32 0 4 0  : 0.94078
16 8 16 4096 64 32 1 8 0  : 0.98886
2 16 16 4096 32 32 0 6 0  : 0.88037
2 32 16 4096 8 8 0 1 0  : 0.82544
2 8 16 4096 32 4 0 3 0  : 0.98277
20 16 16 4096 16 8 4 3 0  : 0.79688
20 16 16 4096 32 8 4 2 0  : 0.83046
20 16 16 4096 64 8 1 4 0  : 0.89711
20 32 16 4096 16 8 1 1 0  : 0.77155
20 32 16 4096 32 8 1 0 0  : 0.7754
20 32 16 4096 64 4 1 3 0  : 0.80607
20 64 16 4096 16 4 1 0 0  : 0.76785
20 64 16 4096 32 4 0 3 0  : 0.76902
20 64 16 4096 64 32 4 2 0  : 0.77451
20 8 16 4096 16 16 4 14 0  : 0.88077
20 8 16 4096 32 32 4 16 0  : 0.94041
20 8 16 4096 64 32 3 24 0  : 0.98929
4 16 16 4096 16 4 0 3 0  : 0.80772
4 32 16 4096 4 4 0 2 0  : 0.80396
4 8 16 4096 16 16 0 8 0  : 0.90156
6 16 16 4096 64 2 0 0 1  : 0.90353
6 64 16 4096 16 2 0 0 1  : 0.78496
6 8 16 4096 64 32 0 13 0  : 0.99916
8 16 16 4096 4 4 1 1 0  : 0.80233
8 32 16 4096 32 32 1 20 0  : 0.78152
8 64 16 4096 2 1 0 0 0  : 0.78861
8 8 16 4096 16 16 0 12 0  : 0.88598

Current fitness: 0.0575789 ... No improvement for 0 generations.

Current fitness: 0.0543151 ... No improvement for 0 generations.

Current fitness: 0.0459811 ... No improvement for 0 generations.

Current fitness: 0.0459811 ... No improvement for 1 generations.

Current fitness: 0.0416671 ... No improvement for 0 generations.

Current fitness: 0.0416627 ... No improvement for 0 generations.

Current fitness: 0.0280656 ... No improvement for 0 generations.

Current fitness: 0.0277551 ... No improvement for 0 generations.

Current fitness: 0.0287242 ... No improvement for 1 generations.

Current fitness: 0.0287242 ... No improvement for 2 generations.

Current fitness: 0.0181298 ... No improvement for 0 generations.

Current fitness: 0.0181298 ... No improvement for 1 generations.

Current fitness: 0.0209508 ... No improvement for 2 generations.

Current fitness: 0.0141441 ... No improvement for 0 generations.

Current fitness: 0.010494 ... No improvement for 0 generations.

Current fitness: 0.0108032 ... No improvement for 1 generations.

Current fitness: 0.0105704 ... No improvement for 2 generations.

Current fitness: 0.00943133 ... No improvement for 0 generations.
70

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00803617 ... No improvement for 0 generations.
86

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00963216 ... No improvement for 1 generations.
70

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00904235 ... No improvement for 2 generations.
64

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00972574 ... No improvement for 3 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00763862 ... No improvement for 0 generations.
51

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00527524 ... No improvement for 0 generations.
63

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
84

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00726002 ... No improvement for 1 generations.
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00726006 ... No improvement for 2 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00632338 ... No improvement for 3 generations.
58

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00700325 ... No improvement for 4 generations.
67

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00635753 ... No improvement for 5 generations.
79

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
79

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
95

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00690378 ... No improvement for 6 generations.
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
95

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
81

WARNING: Too many tuning params for gradient optimization, skipping...
92

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00562366 ... No improvement for 7 generations.
65

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
84

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
88

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00540706 ... No improvement for 8 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
90

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
85

WARNING: Too many tuning params for gradient optimization, skipping...
79

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
90

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00539078 ... No improvement for 9 generations.
55

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00424385 ... No improvement for 0 generations.
56

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00423979 ... No improvement for 0 generations.
59

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
89

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
76

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
89

WARNING: Too many tuning params for gradient optimization, skipping...
82

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00417176 ... No improvement for 0 generations.
61

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
81

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00458312 ... No improvement for 1 generations.
65

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00407043 ... No improvement for 0 generations.
70

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00391966 ... No improvement for 0 generations.
82

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
83

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
85

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00415559 ... No improvement for 1 generations.
66

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00445091 ... No improvement for 2 generations.
55

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00404944 ... No improvement for 3 generations.
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
86

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00445091 ... No improvement for 4 generations.
57

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51
53
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00403159 ... No improvement for 5 generations.
52

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00382485 ... No improvement for 0 generations.
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
79

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00385492 ... No improvement for 1 generations.
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00390602 ... No improvement for 2 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
84

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00354534 ... No improvement for 0 generations.
57

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
83

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00383931 ... No improvement for 1 generations.
55

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.003331 ... No improvement for 0 generations.
56

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00379004 ... No improvement for 1 generations.
66

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
75

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
88

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00358404 ... No improvement for 2 generations.
60

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
79

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
89

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
86

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00322345 ... No improvement for 0 generations.
60

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
89

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
70

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
88

WARNING: Too many tuning params for gradient optimization, skipping...
69

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0032724 ... No improvement for 1 generations.
57

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0031052 ... No improvement for 0 generations.
61

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
77

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
81

WARNING: Too many tuning params for gradient optimization, skipping...
73

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
74

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
78

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00317027 ... No improvement for 1 generations.
58

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
72

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00342748 ... No improvement for 2 generations.
57

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00341075 ... No improvement for 3 generations.
59

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
76

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00358605 ... No improvement for 4 generations.
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00327271 ... No improvement for 5 generations.
55

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
76

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00320224 ... No improvement for 6 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00337582 ... No improvement for 7 generations.
55

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
62

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
68

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00328272 ... No improvement for 8 generations.
52

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
71

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
56

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
61

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
65

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0033133 ... No improvement for 9 generations.
75

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
66

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
53

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
60

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00331332 ... No improvement for 10 generations.
53

WARNING: Too many tuning params for gradient optimization, skipping...
52

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
64

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
80

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...
59

WARNING: Too many tuning params for gradient optimization, skipping...
57

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
63

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
67

WARNING: Too many tuning params for gradient optimization, skipping...
55

WARNING: Too many tuning params for gradient optimization, skipping...
51

WARNING: Too many tuning params for gradient optimization, skipping...
58

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0032663 ... No improvement for 11 generations.

Converged after 66 generations.
