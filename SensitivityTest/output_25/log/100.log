1 16 16 4096 1 1 0 0 0  : 1.2366
12 32 16 4096 64 32 0 0 0  : 0.81286
16 8 16 4096 32 32 0 0 0  : 0.94078
20 32 16 4096 16 16 0 0 0  : 0.77229
4 64 16 4096 64 32 0 0 0  : 0.77895
8 16 16 4096 16 4 0 0 0  : 0.79919
1 16 16 4096 32 32 0 14 0  : 0.9655
1 32 16 4096 16 8 0 1 0  : 0.85477
1 64 16 4096 16 16 0 13 0  : 0.85804
1 64 16 4096 8 4 0 1 0  : 0.87824
1 8 16 4096 64 32 0 8 0  : 1.1778
12 16 16 4096 16 4 3 0 0  : 0.79894
12 16 16 4096 32 32 2 1 0  : 0.83551
12 16 16 4096 4 4 0 0 0  : 0.80215
12 16 16 4096 64 32 3 13 0  : 0.89429
12 16 16 4096 8 8 2 0 1  : 0.79773
12 32 16 4096 16 8 1 0 0  : 0.77481
12 32 16 4096 32 32 2 21 0  : 0.78116
12 32 16 4096 4 4 2 3 0  : 0.7802
12 32 16 4096 64 32 3 25 0  : 0.81286
12 32 16 4096 8 8 3 5 0  : 0.77509
12 64 16 4096 16 8 2 4 0  : 0.77016
12 64 16 4096 32 32 2 5 0  : 0.77155
12 64 16 4096 64 2 3 0 0  : 0.77524
12 64 16 4096 64 32 3 9 0  : 0.77603
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.045823 ... No improvement for 0 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0233203 ... No improvement for 0 generations.
singular matrix A for dgetrf_ in dAx_eq_b_LU()

Current fitness: 0.0333522 ... No improvement for 1 generations.
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()

Current fitness: 0.04265 ... No improvement for 2 generations.

Current fitness: 0.0201777 ... No improvement for 0 generations.
singular matrix A for dgetrf_ in dAx_eq_b_LU()

Current fitness: 0.0241429 ... No improvement for 1 generations.

Current fitness: 0.0239865 ... No improvement for 2 generations.

Current fitness: 0.015324 ... No improvement for 0 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.015324 ... No improvement for 1 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0181356 ... No improvement for 2 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0131795 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00981454 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00932229 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00557993 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00559439 ... No improvement for 1 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00313857 ... No improvement for 0 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00387462 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00432452 ... No improvement for 2 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00407099 ... No improvement for 3 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00408155 ... No improvement for 4 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0037394 ... No improvement for 5 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00206131 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00312578 ... No improvement for 1 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
34
41

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00344575 ... No improvement for 2 generations.
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00302092 ... No improvement for 3 generations.
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00180126 ... No improvement for 0 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00227956 ... No improvement for 1 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00295457 ... No improvement for 2 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00256558 ... No improvement for 3 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00282946 ... No improvement for 4 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00282946 ... No improvement for 5 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00176073 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00176073 ... No improvement for 1 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00176073 ... No improvement for 2 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00176072 ... No improvement for 3 generations.
43

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00176073 ... No improvement for 4 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00169456 ... No improvement for 0 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00163418 ... No improvement for 0 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
54

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00163387 ... No improvement for 1 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00163417 ... No improvement for 2 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
31
27
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00163421 ... No improvement for 3 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00169617 ... No improvement for 4 generations.
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00163382 ... No improvement for 5 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00171606 ... No improvement for 6 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00171622 ... No improvement for 7 generations.
43

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00171624 ... No improvement for 8 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00162588 ... No improvement for 0 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00161813 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32
27

WARNING: Too many tuning params for gradient optimization, skipping...

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00155789 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00161819 ... No improvement for 1 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00171577 ... No improvement for 2 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0016876 ... No improvement for 3 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0017162 ... No improvement for 4 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00150406 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00160852 ... No improvement for 1 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00166576 ... No improvement for 2 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0016661 ... No improvement for 3 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00166568 ... No improvement for 4 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00166576 ... No improvement for 5 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154702 ... No improvement for 6 generations.
45

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154728 ... No improvement for 7 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154728 ... No improvement for 8 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00152545 ... No improvement for 9 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00152545 ... No improvement for 10 generations.
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154513 ... No improvement for 11 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154513 ... No improvement for 12 generations.
40

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
4129


WARNING: Too many tuning params for gradient optimization, skipping...

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154515 ... No improvement for 13 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00154513 ... No improvement for 14 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00146499 ... No improvement for 0 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26
32
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00150025 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00149127 ... No improvement for 2 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00147976 ... No improvement for 3 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00147976 ... No improvement for 4 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00147806 ... No improvement for 5 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00147807 ... No improvement for 6 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00146164 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00128533 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00139594 ... No improvement for 1 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00144034 ... No improvement for 2 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00144035 ... No improvement for 3 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00140269 ... No improvement for 4 generations.
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00136793 ... No improvement for 5 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00136794 ... No improvement for 6 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00136843 ... No improvement for 7 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00140059 ... No improvement for 8 generations.
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 9 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 10 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 11 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 12 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 13 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 14 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
40
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 15 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135558 ... No improvement for 16 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 17 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135543 ... No improvement for 18 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135542 ... No improvement for 19 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00135061 ... No improvement for 20 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00133056 ... No improvement for 21 generations.

Converged after 98 generations.
