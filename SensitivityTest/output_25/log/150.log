1 16 16 4096 1 1 0 0 0  : 1.2366
1 8 16 4096 64 8 0 0 0  : 1.1692
12 8 16 4096 4 2 0 0 0  : 0.84938
16 8 16 4096 32 2 0 0 0  : 0.94197
2 8 16 4096 16 2 0 0 0  : 0.91266
20 64 16 4096 8 4 0 0 0  : 0.76666
4 64 16 4096 4 4 0 0 0  : 0.80063
6 64 16 4096 32 2 0 0 0  : 0.78224
8 32 16 4096 8 8 0 0 0  : 0.77538
1 16 16 4096 32 32 0 11 0  : 0.9655
1 16 16 4096 64 8 0 1 0  : 1.0191
1 32 16 4096 32 32 0 6 0  : 0.85719
1 64 16 4096 16 16 0 1 0  : 0.85804
1 64 16 4096 64 32 0 0 0  : 0.82154
1 8 16 4096 16 8 0 4 0  : 1.0215
1 8 16 4096 64 32 0 31 0  : 1.1778
12 16 16 4096 16 16 2 15 0  : 0.80557
12 16 16 4096 2 1 0 0 0  : 0.81306
12 16 16 4096 32 32 1 6 0  : 0.83551
12 16 16 4096 32 8 0 0 0  : 0.83096
12 16 16 4096 64 32 0 16 0  : 0.89429
12 16 16 4096 64 32 2 8 0  : 0.89429
12 16 16 4096 8 1 0 0 1  : 0.80547
12 32 16 4096 16 16 0 15 0  : 0.77672
12 32 16 4096 16 8 0 0 1  : 0.77481
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.082883 ... No improvement for 0 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0541227 ... No improvement for 0 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0486646 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0476833 ... No improvement for 0 generations.

Current fitness: 0.0446818 ... No improvement for 0 generations.

Current fitness: 0.0361344 ... No improvement for 0 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0276515 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0249502 ... No improvement for 0 generations.

Current fitness: 0.0281376 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.024706 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.023649 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0199223 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0196594 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0209738 ... No improvement for 1 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0182582 ... No improvement for 0 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0123386 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0118452 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.016631 ... No improvement for 1 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00887372 ... No improvement for 0 generations.
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0144537 ... No improvement for 1 generations.
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0123884 ... No improvement for 2 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0184035 ... No improvement for 3 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0172234 ... No improvement for 4 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0162512 ... No improvement for 5 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0161248 ... No improvement for 6 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.016136 ... No improvement for 7 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.013186 ... No improvement for 8 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.017195 ... No improvement for 9 generations.
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.015462 ... No improvement for 10 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0128689 ... No improvement for 11 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0121748 ... No improvement for 12 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00959174 ... No improvement for 13 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0141588 ... No improvement for 14 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0157839 ... No improvement for 15 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0111727 ... No improvement for 16 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.01457 ... No improvement for 17 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0106134 ... No improvement for 18 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00721505 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00721635 ... No improvement for 1 generations.
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0124406 ... No improvement for 2 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0100645 ... No improvement for 3 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00971362 ... No improvement for 4 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00968209 ... No improvement for 5 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00972056 ... No improvement for 6 generations.
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00949455 ... No improvement for 7 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00830245 ... No improvement for 8 generations.
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00946888 ... No improvement for 9 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00724273 ... No improvement for 10 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0088014 ... No improvement for 11 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00981952 ... No improvement for 12 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00905117 ... No improvement for 13 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
3738


WARNING: Too many tuning params for gradient optimization, skipping...

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00792325 ... No improvement for 14 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00863726 ... No improvement for 15 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00905117 ... No improvement for 16 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00857538 ... No improvement for 17 generations.
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
48

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00863811 ... No improvement for 18 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
47

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00823262 ... No improvement for 19 generations.
32
27
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
46

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00822771 ... No improvement for 20 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00823217 ... No improvement for 21 generations.

Converged after 59 generations.
