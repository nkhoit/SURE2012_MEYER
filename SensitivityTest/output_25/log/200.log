1 16 16 4096 1 1 0 0 0  : 1.2366
1 64 16 4096 8 1 0 0 0  : 0.97137
12 32 16 4096 64 2 0 0 0  : 0.80341
16 16 16 4096 32 8 0 0 0  : 0.83034
16 8 16 4096 2 2 0 0 0  : 0.84441
2 64 16 4096 16 2 0 0 0  : 0.81596
20 16 16 4096 8 8 0 0 0  : 0.79273
20 8 16 4096 64 8 0 0 0  : 0.99669
4 64 16 4096 4 1 0 0 0  : 0.81109
6 32 16 4096 2 2 0 0 0  : 0.82829
7 32 16 4096 8 4 0 0 0  : 0.78737
8 64 16 4096 64 8 0 0 0  : 0.77279
1 16 16 4096 32 32 0 0 0  : 0.9655
1 16 16 4096 64 32 0 2 0  : 1.0342
1 32 16 4096 16 2 0 0 0  : 0.88449
1 32 16 4096 4 2 0 1 0  : 0.94535
1 32 16 4096 8 8 0 7 0  : 0.89331
1 64 16 4096 32 32 0 5 0  : 0.83032
1 64 16 4096 64 8 0 3 0  : 0.81048
1 8 16 4096 32 32 0 16 0  : 1.139
1 8 16 4096 64 32 0 27 0  : 1.1778
12 16 16 4096 16 16 0 7 0  : 0.80557
12 16 16 4096 16 4 0 2 0  : 0.79894
12 16 16 4096 32 2 0 0 0  : 0.82515
12 16 16 4096 32 32 1 29 0  : 0.83551
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0512966 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0501083 ... No improvement for 0 generations.
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()
singular matrix A for dgetrf_ in dAx_eq_b_LU()

Current fitness: 0.0479711 ... No improvement for 0 generations.

Current fitness: 0.0421156 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0382339 ... No improvement for 0 generations.

Current fitness: 0.0371195 ... No improvement for 0 generations.

Current fitness: 0.0348675 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.032071 ... No improvement for 0 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0206077 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0186223 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0220457 ... No improvement for 1 generations.

Current fitness: 0.0126359 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0160574 ... No improvement for 1 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0167887 ... No improvement for 2 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0142833 ... No improvement for 3 generations.
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0132018 ... No improvement for 4 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0130827 ... No improvement for 5 generations.
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0126219 ... No improvement for 0 generations.
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0119524 ... No improvement for 0 generations.
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0114948 ... No improvement for 0 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.012409 ... No improvement for 1 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0115808 ... No improvement for 2 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0120295 ... No improvement for 3 generations.
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0108941 ... No improvement for 0 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00766651 ... No improvement for 0 generations.
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0124363 ... No improvement for 1 generations.
29

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0117362 ... No improvement for 2 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00993937 ... No improvement for 3 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0119042 ... No improvement for 4 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0110765 ... No improvement for 5 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0110862 ... No improvement for 6 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0100292 ... No improvement for 7 generations.
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00902514 ... No improvement for 8 generations.
45

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00877035 ... No improvement for 9 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0100792 ... No improvement for 10 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27
26
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0114453 ... No improvement for 11 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00997008 ... No improvement for 12 generations.
39

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.01118 ... No improvement for 13 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.0104501 ... No improvement for 14 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00873662 ... No improvement for 15 generations.
34

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33
40
WARNING: Too many tuning params for gradient optimization, skipping...


WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00844208 ... No improvement for 16 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00844278 ... No improvement for 17 generations.
30

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
39

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00844215 ... No improvement for 18 generations.
33

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
43

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00916036 ... No improvement for 19 generations.
27

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
45

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
41

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
44

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
31

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00909171 ... No improvement for 20 generations.
26

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
36

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
33

WARNING: Too many tuning params for gradient optimization, skipping...
32

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
27

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
40

WARNING: Too many tuning params for gradient optimization, skipping...
35

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
28

WARNING: Too many tuning params for gradient optimization, skipping...
37

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
30

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...
42

WARNING: Too many tuning params for gradient optimization, skipping...
29

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
38

WARNING: Too many tuning params for gradient optimization, skipping...
26

WARNING: Too many tuning params for gradient optimization, skipping...
34

WARNING: Too many tuning params for gradient optimization, skipping...

Current fitness: 0.00815415 ... No improvement for 21 generations.

Converged after 46 generations.
